{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-02T07:04:49.987388Z",
     "start_time": "2024-10-02T07:04:49.983961Z"
    }
   },
   "source": [
    ""
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T07:04:50.124137Z",
     "start_time": "2024-10-02T07:04:50.055653Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import timeit\n",
    "\n",
    "\"\"\"\n",
    "Created on Sat Dec 5 \n",
    "@author: jing0703\n",
    "\n",
    "Data source: \n",
    "https://www.metoffice.gov.uk/research/climate/maps-and-data/historic-station-data\n",
    "\n",
    "Data format:\n",
    "   1914   1    5.2     0.7    ---     52.0    ---\n",
    "   1914   2    9.2     3.5    ---     28.0    ---\n",
    "   1914   3   ---     ---     ---     ---     ---\n",
    "\n",
    "Step:\n",
    "1. Load and parse UK Weather Station History data \n",
    "2. Combine all stations so can run queries across all stations and all time periods \n",
    "3. Summary statistics for stations\n",
    "\n",
    "Package:\n",
    "Spark: 2.3.2\n",
    "Python: 3.6.4\n",
    "\"\"\"\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    main function to parse, clean up and analyze data\n",
    "    \"\"\"\n",
    "    # create empty list to append data and row count for each station\n",
    "    df_all = []\n",
    "    station_count = []\n",
    "    station_list =  [\"aberporth\", \n",
    "                     \"armagh\", \n",
    "                     \"ballypatrick\", \n",
    "                     \"bradford\", \n",
    "                     \"braemar\", \n",
    "                     \"camborne\", \n",
    "                     \"cambridge\", \n",
    "                     \"cardiff\", \n",
    "                     \"chivenor\", \n",
    "                     \"dunstaffnage\", \n",
    "                     \"durham\", \n",
    "                     \"eastbourne\", \n",
    "                     \"eskdalemuir\", \n",
    "                     \"heathrow\", \n",
    "                     \"hurn\", \n",
    "                     \"lerwick\", \n",
    "                     \"leuchars\", \n",
    "                     \"whitby\", \n",
    "                     \"cwmystwyth\", \n",
    "                     \"lowestoft\", \n",
    "                     \"manston\", \n",
    "                     \"nairn\", \n",
    "                     \"newtonrigg\", \n",
    "                     \"oxford\", \n",
    "                     \"paisley\", \n",
    "                     \"ringway\", \n",
    "                     \"rossonwye\", \n",
    "                     \"shawbury\", \n",
    "                     \"sheffield\", \n",
    "                     \"southampton\", \n",
    "                     \"stornoway\", \n",
    "                     \"suttonbonington\", \n",
    "                     \"tiree\", \n",
    "                     \"valley\", \n",
    "                     \"waddington\", \n",
    "                     \"wickairport\", \n",
    "                     \"yeovilton\"]\n",
    "    \n",
    "    start_time = timeit.default_timer()\n",
    "    \n",
    "    # read data for each station and append to list\n",
    "    for station in station_list:\n",
    "        url = f\"https://www.metoffice.gov.uk/pub/data/weather/uk/climate/stationdata/{station}data.txt\"\n",
    "        sc.addFile(url)\n",
    "        rdd = sc.textFile(\"file://\"+ SparkFiles.get(f\"{station}data.txt\"))\n",
    "        df= read_data(rdd, station)\n",
    "        station_count.append(df.count())\n",
    "        df_all.append(df)\n",
    "\n",
    "    # create dict for row count of each station\n",
    "    station_count = dict(zip(station_list, station_count))\n",
    "    print(\"Row count for each station:\", station_count)\n",
    "\n",
    "    # union list of station data into complete df as all history data\n",
    "    df_complete = reduce(DataFrame.unionAll, df_all).cache()\n",
    "    \n",
    "    # climate data analysis for question 4\n",
    "    station_history_rank(df_complete)\n",
    "    station_rain_sun_rank(df_complete)\n",
    "    worst_rain_best_sun(df_complete)\n",
    "    may_avg(df_complete)\n",
    "    best_worst_year_may_climate(df_complete)\n",
    "    \n",
    "    # remove cached df\n",
    "    del df_complete\n",
    "    \n",
    "    # finish timing program \n",
    "    end_time = timeit.default_timer()\n",
    "    print(f\"Program duration: {(end_time - start_time)}s\")\n",
    "\n",
    "\n",
    "def read_data(rdd, station):\n",
    "    \"\"\"\n",
    "    function to remove header line, special character and provisional data\n",
    "    \"\"\"\n",
    "    # list of df column name\n",
    "    new_colnames = [\"station\", \"year\", \"month\", \"tmax\", \"tmin\", \"af\", \"rain\", \"sun\"]\n",
    "    \n",
    "    # find the index for the end of header and  filter out header & special character \n",
    "    head_index = rdd.zipWithIndex().lookup(\"              degC    degC    days      mm   hours\")\n",
    "    cli_data = rdd.zipWithIndex()\\\n",
    "                  .filter(lambda row_index: row_index[1] > head_index[0]).keys()\\\n",
    "                  .filter(lambda x: any(e not in x for e in [\"*\", \"#\", \"$\"])) \n",
    "    \n",
    "    # split rdd, add station name, convert to df  \n",
    "    line_df = cli_data.map(lambda line: (station, line.split(\" \"))).toDF((\"station\", \"data\"))\n",
    "    \n",
    "    # remove empty array from data column \n",
    "    # for spark >= 2.4 use array_remove function\n",
    "    # from pyspark.sql.functions import array_remove\n",
    "    # line_split.withColumn(\"data\", array_remove(\"data\", \"\"))\n",
    "    drop_array = udf(drop_from_array, ArrayType(StringType()))\n",
    "    \n",
    "    # remove rows with extra character for provisional data\n",
    "    df = line_df.withColumn(\"data\", drop_array(\"data\", lit(\"\"))).filter(size(\"data\") == 7)\n",
    "    \n",
    "    # split column data to multiple columns and rename new column\n",
    "    df1 = df.select([df.station] + [df.data[i] for i in range(7)])\n",
    "    df2 = df1.toDF(*new_colnames)\\\n",
    "          .replace(\"---\", None)\\\n",
    "          .na.fill({\"tmax\": 0.0, \"tmin\": 0.0, \"af\": 0, \"rain\": 0.0, \"sun\": 0.0})\\\n",
    "          .withColumn(\"year\",col(\"year\").cast(\"integer\"))\\\n",
    "          .withColumn(\"month\",col(\"month\").cast(\"integer\"))\\\n",
    "          .withColumn(\"tmax\",col(\"tmax\").cast(\"float\"))\\\n",
    "          .withColumn(\"tmin\",col(\"tmin\").cast(\"float\"))\\\n",
    "          .withColumn(\"af\",col(\"af\").cast(\"integer\"))\\\n",
    "          .withColumn(\"rain\",col(\"rain\").cast(\"float\"))\\\n",
    "          .withColumn(\"sun\",col(\"sun\").cast(\"float\")) \\\n",
    "          .cache() \n",
    "\n",
    "    return df2   \n",
    "\n",
    "\n",
    "def drop_from_array(arr, item):\n",
    "    \"\"\"\n",
    "    function to remove item from array\n",
    "    \"\"\"\n",
    "    return [x for x in arr if x != item]\n",
    "\n",
    "\n",
    "def round_column(col_names):\n",
    "    \"\"\"\n",
    "    function to round float from multiple columns\n",
    "    \"\"\"\n",
    "    def inner(df):\n",
    "        for col_name in col_names:\n",
    "            df = df.withColumn(\n",
    "                col_name,\n",
    "                round(df[col_name], 2)\n",
    "            )\n",
    "        return df\n",
    "    return inner\n",
    "\n",
    "\n",
    "\n",
    "def station_history_rank(df_complete):\n",
    "    \"\"\"\n",
    "    a. Rank stations by how long they have been online\n",
    "    \"\"\"\n",
    "    print(\"Rank stations by how long they have been online:\")\n",
    "    \n",
    "    # groupby station & get earliest year/ month by agg\n",
    "    df_online = df_complete.groupBy(\"station\") \\\n",
    "        .agg(\n",
    "             min(\"year\").alias(\"online_y\"), \\\n",
    "             min(\"month\").alias(\"online_m\") \\\n",
    "         ) \\\n",
    "        .orderBy(\"online_y\", \"online_m\")\n",
    "        \n",
    "    # get dense rank of online time with window and ranking functions\n",
    "    window = Window.orderBy(asc(\"online_y\"), asc(\"online_m\"))\n",
    "\n",
    "    df_online_rank = df_online.withColumn(\n",
    "        \"online_time_rank\", \n",
    "        dense_rank().over(window)\n",
    "    ).show(37, truncate = False)\n",
    "\n",
    "\n",
    "\n",
    "def station_rain_sun_rank(df_complete):\n",
    "    \"\"\"\n",
    "    b. Rank stations by rainfall and / or sunshine\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Station rank by total sunshine and rain fall:\")\n",
    "    df_rain_sun = df_complete.groupBy(\"station\") \\\n",
    "                             .agg(\n",
    "                                 sum(\"rain\").alias(\"total_rainfall\"),\\\n",
    "                                 sum(\"sun\").alias(\"total_sunshine\")\n",
    "                             ) \\\n",
    "                             .orderBy(\"total_rainfall\", \"total_sunshine\")\n",
    "\n",
    "    rain_window = Window.orderBy(desc(\"total_rainfall\"))\n",
    "    sun_window = Window.orderBy(desc(\"total_sunshine\"))\n",
    "    \n",
    "    df_rain_sun_rank = df_rain_sun.withColumn(\n",
    "                                    \"rainfall_rank\", \n",
    "                                    dense_rank().over(rain_window)\n",
    "                                 ).withColumn(\n",
    "                                    \"sunshine_rank\", \n",
    "                                    dense_rank().over(sun_window)\n",
    "                                 )\n",
    "    round_column([\"total_rainfall\", \"total_sunshine\"])(df_rain_sun_rank).show(37, truncate = False)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def worst_rain_best_sun(df_complete):\n",
    "    \"\"\"\n",
    "    c. When was the worst rainfall and / or best sunshine for each station\n",
    "    \n",
    "    \"\"\"\n",
    "    print(\"Worst rainfall for each station:\")\n",
    "    df_worst_rain = df_complete.withColumn(\"year_month\", concat(col(\"year\"), lit(\"-\"), col(\"month\")))\\\n",
    "                       .select([\"station\", \"rain\", \"year_month\"])\\\n",
    "                       .groupBy(\"station\", \"year_month\") \\\n",
    "                       .agg(\n",
    "                         sum(\"rain\").alias(\"total_rainfall\")\n",
    "                       ) \\\n",
    "                       .groupBy(\"station\") \\\n",
    "                       .agg(max(struct(col(\"total_rainfall\"), col(\"year_month\"))).alias(\"max_rain\")) \\\n",
    "                       .select(col(\"station\"), col(\"max_rain.year_month\"), col(\"max_rain.total_rainfall\")) \\\n",
    "                       .orderBy(desc(\"max_rain.total_rainfall\")) \n",
    "\n",
    "    round_column([\"total_rainfall\"])(df_worst_rain).show(37, truncate = False)\n",
    "    \n",
    "    print(\"Best sunshine for each station:\")\n",
    "    df_best_sun = df_complete.withColumn(\"year_month\", concat(col(\"year\"), lit(\"-\"), col(\"month\")))\\\n",
    "                   .select([\"station\", \"sun\", \"year_month\"])\\\n",
    "                   .groupBy(\"station\", \"year_month\") \\\n",
    "                   .agg(\n",
    "                     sum(\"sun\").alias(\"total_sunshine\")\n",
    "                   ) \\\n",
    "                   .groupBy(\"station\") \\\n",
    "                   .agg(max(struct(col(\"total_sunshine\"), col(\"year_month\"))).alias(\"max_sun\")) \\\n",
    "                   .select(col(\"station\"), col(\"max_sun.year_month\"), col(\"max_sun.total_sunshine\")) \\\n",
    "                   .orderBy(desc(\"max_sun.total_sunshine\")) \n",
    "                \n",
    "    round_column([\"total_sunshine\"])(df_best_sun).show(37, truncate = False)\n",
    "\n",
    "\n",
    "def may_avg(df_complete):\n",
    "    \"\"\"\n",
    "    d. What are the averages for May across all stations\n",
    "    \n",
    "    \"\"\"\n",
    "    print(\"Average for May across all stations:\")\n",
    "    df_may_avg = df_complete.where(col(\"month\") ==5) \\\n",
    "                            .agg(\n",
    "                                avg(\"tmax\").alias(\"avg_tmax\"), \\\n",
    "                                avg(\"tmin\").alias(\"avg_tmin\"), \\\n",
    "                                avg(\"af\").alias(\"avg_af\"), \\\n",
    "                                avg(\"rain\").alias(\"avg_rain\"), \\\n",
    "                                avg(\"sun\").alias(\"avg_sun\") \\\n",
    "                            )\n",
    "    round_column([\"avg_tmax\", \"avg_tmin\", \"avg_af\", \"avg_rain\", \"avg_sun\"])(df_may_avg).show(truncate = False)\n",
    "\n",
    "\n",
    "def best_worst_year_may_climate(df_complete):\n",
    "    \"\"\"\n",
    "    d. what was the best / worst years for May across all stations\n",
    "    \"\"\"\n",
    "    \n",
    "    # create df for avg climate of May across all stations and groupby year\n",
    "    df_may_avg = df_complete.where(col(\"month\") ==5) \\\n",
    "                            .groupBy(\"year\") \\\n",
    "                            .agg(\n",
    "                                avg(\"tmax\").alias(\"avg_tmax\"), \\\n",
    "                                avg(\"tmin\").alias(\"avg_tmin\"), \\\n",
    "                                avg(\"af\").alias(\"avg_af\"), \\\n",
    "                                avg(\"rain\").alias(\"avg_rain\"), \\\n",
    "                                avg(\"sun\").alias(\"avg_sun\") \\\n",
    "                            ) \\\n",
    "                            .orderBy(\"year\").cache()\n",
    "                \n",
    "    # create window by asc & desc for average temp/ af/ sunshine/ rainfall\n",
    "    tmax_window = Window.orderBy(desc(\"avg_tmax\"))\n",
    "    tmin_window = Window.orderBy(asc(\"avg_tmin\"))\n",
    "    af_desc_window = Window.orderBy(desc(\"avg_af\"))\n",
    "    af_asc_window = Window.orderBy(asc(\"avg_af\"))\n",
    "    sun_desc_window = Window.orderBy(desc(\"avg_sun\"))\n",
    "    sun_asc_window = Window.orderBy(asc(\"avg_sun\"))\n",
    "    rain_desc_window = Window.orderBy(desc(\"avg_rain\"))\n",
    "    rain_asc_window = Window.orderBy(asc(\"avg_rain\"))\n",
    "    \n",
    "    print(\"Best and worst year of temperature for May:\")\n",
    "    may_tmax_max = df_may_avg.withColumn(\n",
    "                            \"tmax_rank\", \n",
    "                            dense_rank().over(tmax_window)\n",
    "                          ).select(\"year\", \"avg_tmax\") \\\n",
    "                          .filter(col(\"tmax_rank\") == 1) \\\n",
    "                          .withColumnRenamed(\"avg_tmax\",\"may_temp_max\") \\\n",
    "                          .withColumn(\"may_temp_max\", round(\"may_temp_max\", 2)) \\\n",
    "                          .show()\n",
    "                \n",
    "    may_tmin_min = df_may_avg.withColumn(\n",
    "                                \"tmin_rank\", \n",
    "                                dense_rank().over(tmin_window)\n",
    "                              ).select(\"year\", \"avg_tmin\") \\\n",
    "                              .filter(col(\"tmin_rank\") == 1) \\\n",
    "                              .withColumnRenamed(\"avg_tmin\",\"may_temp_min\") \\\n",
    "                              .withColumn(\"may_temp_min\", round(\"may_temp_min\", 2)) \\\n",
    "                              .show()\n",
    "                    \n",
    "    print(\"Best and worst year of days of air frost for May:\")\n",
    "    may_af_max = df_may_avg.withColumn(\n",
    "                            \"af_rank\", \n",
    "                            dense_rank().over(af_desc_window)\n",
    "                        ).select(\"year\", \"avg_af\") \\\n",
    "                        .filter(col(\"af_rank\") == 1) \\\n",
    "                        .withColumnRenamed(\"avg_af\",\"may_af_max\") \\\n",
    "                        .withColumn(\"may_af_max\", round(\"may_af_max\", 2)) \\\n",
    "                        .show()\n",
    "\n",
    "\n",
    "    may_af_min = df_may_avg.withColumn(\n",
    "                              \"af_rank\", \n",
    "                              dense_rank().over(af_asc_window)\n",
    "                            ).select(\"year\", \"avg_af\") \\\n",
    "                            .filter(col(\"af_rank\") == 1) \\\n",
    "                            .withColumnRenamed(\"avg_af\",\"may_af_min\").show()\n",
    "            \n",
    "    print(\"Best and worst year of sunshine for May:\")\n",
    "    may_sun_max = df_may_avg.withColumn(\n",
    "                            \"sun_rank\", \n",
    "                            dense_rank().over(sun_desc_window)\n",
    "                        ).select(\"year\", \"avg_sun\") \\\n",
    "                        .filter(col(\"sun_rank\") == 1) \\\n",
    "                        .withColumnRenamed(\"avg_sun\",\"may_sun_max\") \\\n",
    "                        .withColumn(\"may_sun_max\", round(\"may_sun_max\", 2)) \\\n",
    "                        .show()\n",
    "\n",
    "    may_sun_min = df_may_avg.withColumn(\n",
    "                                \"sun_rank\", \n",
    "                                dense_rank().over(sun_asc_window)\n",
    "                             ).select(\"year\", \"avg_sun\") \\\n",
    "                            .filter(col(\"sun_rank\") == 1) \\\n",
    "                            .withColumnRenamed(\"avg_sun\",\"may_sun_min\").show()\n",
    "            \n",
    "    print(\"Best and worst year of rainfall for May:\")\n",
    "    may_rain_max = df_may_avg.withColumn(\n",
    "                            \"rain_rank\", \n",
    "                            dense_rank().over(rain_desc_window)\n",
    "                        ).select(\"year\", \"avg_rain\") \\\n",
    "                        .filter(col(\"rain_rank\") == 1) \\\n",
    "                        .withColumnRenamed(\"avg_rain\",\"may_rain_max\") \\\n",
    "                        .withColumn(\"may_rain_max\", round(\"may_rain_max\", 2)) \\\n",
    "                        .show()\n",
    "\n",
    "\n",
    "    may_rain_min = df_may_avg.withColumn(\n",
    "                                \"rain_rank\", \n",
    "                                dense_rank().over(rain_asc_window)\n",
    "                             ).select(\"year\", \"avg_rain\") \\\n",
    "                             .filter(col(\"rain_rank\") == 1) \\\n",
    "                             .withColumnRenamed(\"avg_rain\",\"may_rain_min\") \\\n",
    "                             .withColumn(\"may_rain_min\", round(\"may_rain_min\", 2)) \\\n",
    "                             .show()"
   ],
   "id": "c2c565193f2feb6c",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-02T07:04:50.193169Z",
     "start_time": "2024-10-02T07:04:50.189434Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "c314df0547a89dec",
   "outputs": [],
   "execution_count": 3
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
